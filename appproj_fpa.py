# -*- coding: utf-8 -*-
"""appProj_FPA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rKmqYzidE1aJYXbflI_0nAMhA_xS_URP
"""

from flask import Flask, request, jsonify
import pickle
import re
import os

app = Flask(__name__)

# Load model and vectorizer
MODEL_VERSION = os.getenv('MODEL_VERSION', '1.0')
model = None
vectorizer = None

def load_models():
    """Load the trained model and vectorizer"""
    global model, vectorizer
    try:
        with open(f'models/model_v{MODEL_VERSION}.pkl', 'rb') as f:
            model = pickle.load(f)
        with open(f'models/vectorizer_v{MODEL_VERSION}.pkl', 'rb') as f:
            vectorizer = pickle.load(f)
        print(f"Model version {MODEL_VERSION} loaded successfully")
    except Exception as e:
        print(f"Error loading model: {e}")
        raise

def clean_tweet(text):
    """Clean and preprocess tweet text"""
    text = text.lower()
    text = re.sub(r'http\S+|www\S+|https\S+', '', text, flags=re.MULTILINE)
    text = re.sub(r'@\w+', '', text)
    text = re.sub(r'#', '', text)
    text = re.sub(r'[^a-zA-Z\s]', '', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text

@app.route('/')
def home():
    """Health check endpoint"""
    return jsonify({
        'status': 'running',
        'model_version': MODEL_VERSION,
        'message': 'Sentiment Analysis API is running'
    })

@app.route('/health')
def health():
    """Detailed health check"""
    return jsonify({
        'status': 'healthy',
        'model_loaded': model is not None,
        'vectorizer_loaded': vectorizer is not None,
        'model_version': MODEL_VERSION
    })

@app.route('/predict', methods=['POST'])
def predict():
    """Predict sentiment of a tweet"""
    try:
        # Get tweet from request
        data = request.get_json()

        if not data or 'tweet' not in data:
            return jsonify({
                'error': 'No tweet provided. Please send JSON with "tweet" field'
            }), 400

        tweet = data['tweet']

        if not tweet or not tweet.strip():
            return jsonify({
                'error': 'Tweet cannot be empty'
            }), 400

        # Clean tweet
        cleaned_tweet = clean_tweet(tweet)

        if not cleaned_tweet:
            return jsonify({
                'error': 'Tweet contains no valid text after cleaning'
            }), 400

        # Vectorize and predict
        tweet_vector = vectorizer.transform([cleaned_tweet])
        prediction = model.predict(tweet_vector)[0]
        prediction_proba = model.predict_proba(tweet_vector)[0]

        # Map prediction to sentiment
        sentiment_map = {0: 'negative', 1: 'positive'}
        sentiment = sentiment_map[prediction]

        # Get confidence
        confidence = float(max(prediction_proba))

        return jsonify({
            'tweet': tweet,
            'cleaned_tweet': cleaned_tweet,
            'sentiment': sentiment,
            'confidence': confidence,
            'probabilities': {
                'negative': float(prediction_proba[0]),
                'positive': float(prediction_proba[1])
            },
            'model_version': MODEL_VERSION
        })

    except Exception as e:
        return jsonify({
            'error': f'Prediction failed: {str(e)}'
        }), 500

@app.route('/batch_predict', methods=['POST'])
def batch_predict():
    """Predict sentiment for multiple tweets"""
    try:
        data = request.get_json()

        if not data or 'tweets' not in data:
            return jsonify({
                'error': 'No tweets provided. Please send JSON with "tweets" array'
            }), 400

        tweets = data['tweets']

        if not isinstance(tweets, list):
            return jsonify({
                'error': 'Tweets must be an array'
            }), 400

        if len(tweets) == 0:
            return jsonify({
                'error': 'Tweets array cannot be empty'
            }), 400

        # Process all tweets
        results = []
        for tweet in tweets:
            cleaned_tweet = clean_tweet(tweet)

            if not cleaned_tweet:
                results.append({
                    'tweet': tweet,
                    'error': 'No valid text after cleaning'
                })
                continue

            tweet_vector = vectorizer.transform([cleaned_tweet])
            prediction = model.predict(tweet_vector)[0]
            prediction_proba = model.predict_proba(tweet_vector)[0]

            sentiment_map = {0: 'negative', 1: 'positive'}
            sentiment = sentiment_map[prediction]
            confidence = float(max(prediction_proba))

            results.append({
                'tweet': tweet,
                'sentiment': sentiment,
                'confidence': confidence
            })

        return jsonify({
            'results': results,
            'count': len(results),
            'model_version': MODEL_VERSION
        })

    except Exception as e:
        return jsonify({
            'error': f'Batch prediction failed: {str(e)}'
        }), 500

if __name__ == '__main__':
    load_models()
    app.run(host='0.0.0.0', port=5000, debug=False)