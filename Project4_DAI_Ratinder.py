# -*- coding: utf-8 -*-
"""Untitled32.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uLhHei0Tb4jLLfZrUKkNW2Q4NVRD0DYz
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import load_digits
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE

digits = load_digits()
X = digits.data # Each image is flattened into a 64-length vector (8x8 images)
y = digits.target # True labels (0–9) — only for evaluation/visualization

print("Data shape:", X.shape)
print("Labels shape:", y.shape)




# Step 3 — Plot some sample images - optional
plt.figure(figsize=(8, 4))
for i in range(10):
    plt.subplot(2, 5, i+1)
    plt.imshow(X[i].reshape(8,8), cmap='gray')  # reshape 64 → 8x8 image
    plt.title(f"Label: {y[i]}")
    plt.axis('off')
plt.suptitle("Sample MNIST Images")
plt.show()

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Step 4 — Determine optimal number of clusters (Elbow Method)
inertia = []#- sum of squatred distance to the center
K = range(5, 16)  # Try k from 5 to 15
for k in K:
    km = KMeans(n_clusters=k, random_state=42, n_init=10)
    km.fit(X_scaled)
    inertia.append(km.inertia_)

# Plot elbow curve
plt.figure(figsize=(8,4))
plt.plot(K, inertia, marker='o')
plt.title("Elbow Method for Optimal k")
plt.xlabel("Number of clusters")
plt.ylabel("Inertia")
plt.show()

k = 10
kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
clusters = kmeans.fit_predict(X_scaled)

plt.figure(figsize=(12,5))
for i in range(k):
  plt.subplot(2,5,i+1)
  plt.imshow(kmeans.cluster_centers_[i].reshape(8,8), cmap='gray')
  plt.title(f"Cluster {i}")
  plt.axis('off')
  plt.suptitle("K-Means Cluster Centroids")
  plt.show()

pca = PCA(n_components=2, random_state=42)
X_pca = pca.fit_transform(X_scaled)

plt.figure(figsize=(8,6))
for i in range(k):
  plt.scatter(X_pca[clusters==i,0], X_pca[clusters==i,1], label=f"Cluster {i}", alpha=0.6)
  plt.title("K-Means Clusters (PCA-reduced 2D)")
  plt.legend()
  plt.show()

tsne = TSNE(n_components=2, random_state=42, learning_rate='auto', init='random')
X_tsne = tsne.fit_transform(X_scaled)

plt.figure(figsize=(8,6))
for i in range(k):
  plt.scatter(X_tsne[clusters==i,0], X_tsne[clusters==i,1], label=f"Cluster {i}", alpha=0.6)
  plt.title("K-Means Clusters (t-SNE-reduced 2D)")
  plt.legend()
  plt.show()

plt.figure(figsize=(8,6))
for digit in range(10):
  plt.scatter(X_pca[y==digit,0], X_pca[y_true==digit,1], label=f"Digit {digit}", alpha=0.6)
  plt.title("True Digits (PCA-reduced 2D)")
  plt.legend()
  plt.show()